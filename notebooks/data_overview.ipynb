{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9814b4e",
   "metadata": {},
   "source": [
    "## Quick setup\n",
    "\n",
    "Recommended: use the project's environment managed by `uv`. Example commands:\n",
    "\n",
    "```bash\n",
    "uv sync\n",
    "uv run python -m pip install plotly duckdb\n",
    "```\n",
    "\n",
    "If you prefer SQL-style analytics without importing CSVs into a database, `duckdb` is a great option (it can query CSVs directly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8657a34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and versions\n",
    "import sys, platform, subprocess\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import duckdb\n",
    "\n",
    "print('Python:', sys.version.splitlines()[0])\n",
    "print('Pandas:', pd.__version__)\n",
    "print('Plotly:', plotly.__version__)\n",
    "print('DuckDB:', duckdb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480ca4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to key CSVs\n",
    "DATA_DOCS = 'document_stats.csv'\n",
    "DATA_FILES = 'document_stats-files.csv'\n",
    "DATA_LANG = 'Documents/language-check-report.csv'\n",
    "\n",
    "# Load (these are small enough to load into memory in this repo)\n",
    "docs = pd.read_csv(DATA_DOCS)\n",
    "files = pd.read_csv(DATA_FILES)\n",
    "lang = pd.read_csv(DATA_LANG)\n",
    "\n",
    "docs.shape, files.shape, lang.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc8033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick heads and basic stats\n",
    "display(docs.head())\n",
    "display(docs.describe(include='all'))\n",
    "\n",
    "display(files.head())\n",
    "display(files['Pages'].describe())\n",
    "\n",
    "display(lang.head())\n",
    "print('Language-check issues by type:')\n",
    "print(lang['Type'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5fbe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example plot: PDFs per subject (from document_stats.csv)\n",
    "fig = px.bar(docs, x='Subject', y='PDFs', title='PDFs per subject')\n",
    "fig.update_layout(xaxis={'categoryorder':'total descending'}, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c406ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of pages per file (document_stats-files.csv)\n",
    "fig = px.histogram(files, x='Pages', nbins=30, title='Distribution of pages per file')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ffdd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join example: verify per-subject page totals\n",
    "files_by_subject = files.groupby('Subject', as_index=False)['Pages'].sum().rename(columns={'Pages':'Pages_files'})\n",
    "merged = pd.merge(docs, files_by_subject, on='Subject', how='left')\n",
    "merged['Pages_diff'] = merged['Pages'] - merged['Pages_files']\n",
    "display(merged[['Subject','Pages','Pages_files','Pages_diff']].sort_values('Pages_diff', key=abs, ascending=False).head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7741e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top subjects by language-check issues (quick summary)\n",
    "top_issues = lang.groupby('Subject').size().reset_index(name='n').sort_values('n', ascending=False).head(25)\n",
    "fig = px.bar(top_issues, x='Subject', y='n', title='Top subjects by language-check issues')\n",
    "fig.update_layout(xaxis={'categoryorder':'total descending'}, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f931eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a small processed summary for quick reference\n",
    "import os\n",
    "os.makedirs('notebooks', exist_ok=True)\n",
    "merged.to_csv('notebooks/processed_summary.csv', index=False)\n",
    "print('Wrote notebooks/processed_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3440df87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility: git commit and environment\n",
    "try:\n",
    "    sha = subprocess.check_output(['git','rev-parse','--short','HEAD']).decode().strip()\n",
    "except Exception:\n",
    "    sha = '<not available>'\n",
    "print('Git commit:', sha)\n",
    "print('Platform:', platform.platform())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7d8696",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "- Add a DuckDB-powered cell for SQL analytics without fully loading very large CSVs.\n",
    "- Add more focused visualisations (issue types over time, heatmaps by rule ID, per-file issue density).\n",
    "- Optionally add `nbval` or `papermill` based CI to execute this notebook in CI and ensure it runs without errors."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
