{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6501ed4c",
   "metadata": {},
   "source": [
    "---\n",
    "hide:\n",
    "  - navigation\n",
    "  - toc\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8657a34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared setup\n",
    "%run _shared/setup_data_overview.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd840ad",
   "metadata": {},
   "source": [
    "# Proofreader Data Overview\n",
    "\n",
    "This count of issues shows a count of all spelling, grammar, factual accuracy and consistency issues found across the entire corpus with a confidence score of 0.8 or higher. This gives us a total count of the issues that the LLM is most confident are real issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6ac1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Total Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b002a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Filter issues by category and confidence score >= 80\n",
    "filtered_issues = issues[\n",
    "    (issues['Issue Category'].isin(['Spelling', 'Grammar', 'Factual', 'Consistency'])) &\n",
    "    (issues['Confidence Score'] >= 80)\n",
    "]\n",
    "\n",
    "# Count issues by category\n",
    "issue_counts = filtered_issues['Issue Category'].value_counts(\n",
    ").sort_values(ascending=False)\n",
    "summary_table = pd.DataFrame({\n",
    "    'Issue Category': issue_counts.index,\n",
    "    'Count': issue_counts.values\n",
    "})\n",
    "\n",
    "display(summary_table)\n",
    "display(\n",
    "    Markdown(f\"**Total issues (with confidence ≥ 80):** {len(filtered_issues)}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be9128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an interactive bar chart using Plotly\n",
    "import plotly.express as px\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "fig = px.bar(\n",
    "    summary_table,\n",
    "    x='Issue Category',\n",
    "    y='Count',\n",
    "    title='Issue Count by Category (Confidence Score ≥ 80)',\n",
    "    labels={'Issue Category': 'Category', 'Count': 'Number of Issues'},\n",
    "    color='Count',\n",
    "    color_continuous_scale='Viridis',\n",
    "    text='Count'\n",
    ")\n",
    "\n",
    "# Update layout for better appearance\n",
    "fig.update_traces(textposition='outside')\n",
    "fig.update_layout(\n",
    "    height=500,\n",
    "    showlegend=False,\n",
    "    xaxis_tickangle=-45,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "# Emit as HTML so mkdocs-jupyter/MkDocs can render it\n",
    "display(HTML(fig.to_html(full_html=False, include_plotlyjs='cdn')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841eec02",
   "metadata": {},
   "source": [
    "## Issues Per Page by Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec5622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Calculate average issues per page across entire corpus\n",
    "total_issues = len(filtered_issues)\n",
    "total_pages = files['Pages'].sum()\n",
    "avg_issues_per_page_overall = total_issues / total_pages\n",
    "\n",
    "display(Markdown(f\"\"\"### Average Issues Per Page (Entire Corpus):\n",
    "\n",
    "- **Total Issues**: {total_issues}\n",
    "- **Total Pages**: {total_pages}\n",
    "- **Average Issues Per Page**: {avg_issues_per_page_overall:.4f}\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ecf6f1",
   "metadata": {},
   "source": [
    "## Average Issues Per Page by Subject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eb4104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Calculate average issues per page by subject\n",
    "subject_issues = filtered_issues.groupby(\n",
    "    'Subject').size().reset_index(name='Issue Count')\n",
    "\n",
    "# Normalize subject names in files (replace hyphens with spaces)\n",
    "files_normalized = files.copy()\n",
    "files_normalized['Subject'] = files_normalized['Subject'].str.replace('-', ' ')\n",
    "\n",
    "subject_pages = files_normalized.groupby(\n",
    "    'Subject')['Pages'].sum().reset_index(name='Total Pages')\n",
    "\n",
    "subject_stats = subject_issues.merge(subject_pages, on='Subject', how='left')\n",
    "subject_stats['Issues Per Page'] = (\n",
    "    subject_stats['Issue Count'] / subject_stats['Total Pages']).round(2)\n",
    "subject_stats = subject_stats.sort_values('Issues Per Page', ascending=False)\n",
    "\n",
    "display(subject_stats[['Subject', 'Issue Count',\n",
    "        'Total Pages', 'Issues Per Page']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c5cafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a horizontal bar chart sorted by issues per page\n",
    "# Reverse sort for chart display (ascending) so highest values appear at top\n",
    "import plotly.express as px\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "chart_data = subject_stats.sort_values('Issues Per Page', ascending=True)\n",
    "\n",
    "fig_subject = px.bar(\n",
    "    chart_data,\n",
    "    x='Issues Per Page',\n",
    "    y='Subject',\n",
    "    orientation='h',\n",
    "    title='Average Issues Per Page by Subject (Highest to Lowest)',\n",
    "    labels={'Issues Per Page': 'Issues Per Page', 'Subject': 'Subject'},\n",
    "    color='Issues Per Page',\n",
    "    color_continuous_scale='Viridis',\n",
    "    text='Issues Per Page'\n",
    ")\n",
    "\n",
    "# Update layout for better appearance\n",
    "fig_subject.update_traces(textposition='outside')\n",
    "fig_subject.update_layout(\n",
    "    height=700,\n",
    "    showlegend=False,\n",
    "    hovermode='y unified'\n",
    ")\n",
    "\n",
    "# Emit as HTML so mkdocs-jupyter/MkDocs can render it\n",
    "display(HTML(fig_subject.to_html(full_html=False, include_plotlyjs='cdn')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626ccbfb",
   "metadata": {},
   "source": [
    "## Sample Issues by Category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c696ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Filter issues by category and confidence score >= 80\n",
    "filtered_issues_sample = issues[\n",
    "    (issues['Issue Category'].isin(['Spelling', 'Grammar', 'Factual', 'Consistency'])) &\n",
    "    (issues['Confidence Score'] >= 80)\n",
    "] .copy()\n",
    "\n",
    "# Sample 2 issues from each category\n",
    "sample_issues = []\n",
    "for category in ['Spelling', 'Grammar', 'Factual', 'Consistency']:\n",
    "    category_issues = filtered_issues_sample[filtered_issues_sample['Issue Category'] == category]\n",
    "    if len(category_issues) >= 2:\n",
    "        sampled = category_issues.sample(\n",
    "            n=min(2, len(category_issues)), random_state=42)\n",
    "    else:\n",
    "        sampled = category_issues\n",
    "    sample_issues.append(sampled)\n",
    "\n",
    "sample_df = pd.concat(sample_issues, ignore_index=True)\n",
    "\n",
    "\n",
    "def _md_escape_table_cell(value: object) -> str:\n",
    "    if value is None or (isinstance(value, float) and pd.isna(value)):\n",
    "        return \"N/A\"\n",
    "    text = str(value)\n",
    "    text = text.replace(\"|\", \"\\\\|\")\n",
    "    text = \" \".join(text.splitlines()).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "# Emit a *real* Markdown output (not stdout) so MkDocs can render it\n",
    "md_lines: list[str] = []\n",
    "md_lines.append(\"## Two Random Issues from Each Category\")\n",
    "md_lines.append(\"\")\n",
    "md_lines.append(\n",
    "    \"| Subject | Document | Pg | Context | Issue | Confidence | Reasoning      |\")\n",
    "md_lines.append(\n",
    "    \"|---------|----------|----|---------|-------|------------|----------------|\")\n",
    "\n",
    "for _, row in sample_df.iterrows():\n",
    "    subject = _md_escape_table_cell(row.get('Subject'))\n",
    "    doc_name = _md_escape_table_cell(row.get('Document Name'))\n",
    "    page_num = _md_escape_table_cell(row.get('Page Number'))\n",
    "    category = _md_escape_table_cell(row.get('Issue Category'))\n",
    "    conf_score = _md_escape_table_cell(row.get('Confidence Score'))\n",
    "    reasoning = _md_escape_table_cell(row.get('Reasoning'))\n",
    "    context = _md_escape_table_cell(row.get('Context'))\n",
    "    md_lines.append(\n",
    "        f\"| {subject} | {doc_name} | {page_num} | {context} | {category} | {conf_score} | {reasoning} |\")\n",
    "\n",
    "md_lines.append(\"\")\n",
    "md_lines.append(f\"Total issues displayed: {len(sample_df)}\")\n",
    "\n",
    "display(Markdown(\"\\n\".join(md_lines)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wjecdocumentscraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
